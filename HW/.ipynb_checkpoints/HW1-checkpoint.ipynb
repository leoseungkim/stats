{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Review of Inferential Statistics & Introduction to Model Comparison\n",
    "\n",
    "## PSYC5501: Experimental Design & Statistics\n",
    "\n",
    "### Seung Kim, 29 September 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. A set of reading scores for fourth grade students has a mean of 25 and a standard deviation of 5. A set of scores for ninth grade students has a mean of 30 and a standard deviation of 10. Assume that the distributions are normal.**\n",
    "\n",
    "\n",
    "**A. What percentage of the fourth graders score better than the average ninth grader?**\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution.** The average reading score for fourth graders is 25 with a standard deviation of 5; the average score for ninth graders is 30, which is exactly at the first standard deviation of the distribution of the fourth graders' reading scores. This means that the portion of fourth graders with scores at $z > 1$ have scored better than the average ninth grader.\n",
    "\n",
    "Or, more mechanically,\n",
    "\n",
    "$$z = \\frac{30-25}{5} = 1$$\n",
    "\n",
    "Looking at the z-table, we see that the area of the right tail ('better than') bounded by $z = 1$ is 0.1587. Therefore, the percentage of fourth graders who score better than the average ninth grader is 15.9%. We can use R to double-check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.158655253931457"
      ],
      "text/latex": [
       "0.158655253931457"
      ],
      "text/markdown": [
       "0.158655253931457"
      ],
      "text/plain": [
       "[1] 0.1586553"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pnorm(30, mean=25, sd=5, lower.tail=FALSE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. What percentage of ninth graders score worse than the average fourth grader?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution.** The average reading score for ninth graders is 30 with a standard deviation of 10; the average score for fourth graders is 25. The score of 25 is at the -0.5th standard deviation of the distribution of ninth graders' scores. This means that the portion of ninth graders with scores at z < -0.5 have scored worse than the average fourth grader.\n",
    "\n",
    "More mechanically:\n",
    "\n",
    "$$z = \\frac{25-30}{10} = -0.5$$\n",
    "\n",
    "Looking at the z-table again, we see that the area of the left tail ('worse than') bounded by z = -0.5 is 0.3085. Therefore, the percentage of ninth graders who score worse than the average fourth grader is 30.1%. We can again use R to double-check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.308537538725987"
      ],
      "text/latex": [
       "0.308537538725987"
      ],
      "text/markdown": [
       "0.308537538725987"
      ],
      "text/plain": [
       "[1] 0.3085375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pnorm(25, mean=30, sd=10, lower.tail=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Describe the relationships among a population distribution, a sample distribution, and a sampling distribution. What does the Central Limit Theorem tell us about the sampling distribution for a given population?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution.** \n",
    "\n",
    "* The **population distribution** is the distribution of every individual score in the population at study. The population distribution is rarely available in full, and may follow many distributional shapes (though most that are relevant to social sciences are assumed to be distributed normally). \n",
    "* The **sample distribution** is the distribution of individual scores within *one* sample. Given a large enough sample size, the sample shape and statistics tend to mirror the population shape and parameters, including mean and variance, though samples always come with sampling error—unless all scores in the population are the same or our sample is equal to the population (we somehow manage to get every single individual), the sample statistics will always be different from the population parameters. \n",
    "* The **sampling distribution** is the distribution of a statistic gathered from multiple samples of a population. We are most concerned with the sampling distribution of means—the distribution of means of repeated samples from the same population—because, according to the **Central Limit Theorem**, the sampling distribution approaches a normal distribution as the sample size increases, regardless of the shape of the population distribution. This is advantageous because, given a large enough sample size, we can use the normality of the sampling distribution to make inferences about the probability of obtaining a sample mean even if the population is non-normal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. A recently admitted class of graduate students at a large state university has a mean GRE verbal score of 650 with a standard deviation of 50. The scores are reasonably normally distributed. Five students have parents who happen to be on the board of trustees, and these students were admitted with a mean GRE score of 550. Should the local newspaper editor write a scathing editorial about favoritism? Assume that you are only interested in whether this group of students has a lower GRE than the university average.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution.** We would like to see whether the five well-connected students belong to the population of recently admitted graduate students or a different population with a lower GRE average. We can articulate the hypotheses as follows:\n",
    "\n",
    "* $H_0: \\mu = 650$\n",
    "* $H_1: \\mu < 650$ (not $\\neq$ because we're only concerned whether the sample is lower)\n",
    "\n",
    "~~Since we know both the population mean and standard deviation, we can perform a $z$-test; and since you specified that we only care whether this group has a lower GRE than the average, we go with a one-tailed test.~~\n",
    "\n",
    "~~Even from just looking at the facts, we can see that the sample mean of 550 is two standard deviations lower than the population mean of 650. We can calculate the $z$-score mechanically just to be thorough: $z = \\frac{550-650}{50} = -2$.~~\n",
    "\n",
    "We need to use the standard error here, because \n",
    "\n",
    "Looking at the $z$-table, we see that the area of the lower tail (the $p$-value) bounded by $z=-2$ is $0.0228$. This means that we have a 2.3% probability of seeing an individual with a score as low or lower than 550 given that they are in the $\\mu=650$ population. That is more extreme than the (arbitrary) $\\alpha=0.05$ threshold. Even if we were to increase the rigor by doing a two-tailed test, $0.0228$ is still more extreme than $0.025$. So, we have a solid basis for rejecting $H_0$—the five well-connected students are from a population with a mean that is lesser than 650. The local newspaper should go ham on them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Provide a precise definition of the conditional probability that you obtained in #3.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution.** The $p$-value we obtained (0.0228) is the probability that we observe a sample mean of 550 or less given that the population from which the sample was collected has a mean of 650 (i.e. given that the $H_0$ is true).\n",
    "\n",
    "$$p = P(X\\leq550|\\mu=650)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Can repressed anger lead to higher blood pressure? In a hypothetical study, 6 college students with very high repressed anger scores (derived from a series of questionnaires taken in an introductory psychology class) are called in to have their blood pressure measured. The systolic blood pressure readings for the 6 students are 115, 118, 127, 129, 135, and 126. If the mean systolic blood pressure in the population is 120, can you conclude that repressed anger is associated with higher blood pressure? Carry out a one-sample t-test to address this question. Use α=.05 and conduct a two-tailed test. Be sure to state the null and alternative hypotheses.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution.** We begin by articulating our hypotheses. We want to find out whether students with very high repressed anger scores have higher blood pressures than the general population of students. \n",
    "\n",
    "* $H_0: \\mu = 120$ \n",
    "* $H_1: \\mu \\neq 120$ (not $>$ because this is a two-tailed test)\n",
    "\n",
    "Then we can carry out a one-sample, two-tailed t-test as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = c(115, 118, 127, 129, 135, 126) # sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 120                 # population mean\n",
    "s = sd(X)                # StDev of sample\n",
    "se = s/sqrt(length(X))   # SE of sampling distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1.66666666666667"
      ],
      "text/latex": [
       "1.66666666666667"
      ],
      "text/markdown": [
       "1.66666666666667"
      ],
      "text/plain": [
       "[1] 1.666667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = (mean(X) - mu)/se\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $\\alpha = 0.05$, $\\text{df}=n-1=5$ and we are conducting a two-tailed test, our $t_{0.025, 5} = 2.571$—that is, we consider the mean sample blood pressure to be significantly different from the mean population blood pressure if our experimental $t > 2.571$ or $t < -2.571$. Since $t=1.667$ does not satisfy either of these criteria, we reject $H_1$ and retain the $H_0$. \n",
    "\n",
    "We can confirm using R's built-in `t.test` function. The $p$-value (0.1565) is less extreme than $\\alpha =0.05$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tOne Sample t-test\n",
       "\n",
       "data:  X\n",
       "t = 1.6667, df = 5, p-value = 0.1565\n",
       "alternative hypothesis: true mean is not equal to 120\n",
       "95 percent confidence interval:\n",
       " 117.2883 132.7117\n",
       "sample estimates:\n",
       "mean of x \n",
       "      125 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.test(X, mu=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Use the general linear model approach to answer the same question that is asked in #5. Be sure to fully write out the full and restricted models, and show all of your steps.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution.** The GLM approach compares two models, one 'complex' and one 'simple', to see whether the simpler model has a substantially worse fit that the complex one. The complex model estimates factors, while the simpler model does not assume anything (*I think it would be nice to have this explained more*).\n",
    "\n",
    "* Full: $Y_i = \\bar{Y} + \\epsilon_i$\n",
    "* Restricted: $Y_i = \\mu + \\epsilon_i$\n",
    "\n",
    "\n",
    "We have six scores: 115, 118, 127, 129, 135, and 126, of which the sample mean is 125. The population mean is 120. So, we can set up the following complex (full) and simple (restricted) models:\n",
    "\n",
    "* Full: $Y_i = 125 + \\epsilon_i$\n",
    "* Restricted: $Y_i = 120 + \\epsilon_i$\n",
    "\n",
    "The goal is to see whether these two differ significantly enough. To do this, we need the sums of individual squared errors from both models and their degrees of freedom. First, let's get the sums:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "270"
      ],
      "text/latex": [
       "270"
      ],
      "text/markdown": [
       "270"
      ],
      "text/plain": [
       "[1] 270"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Full model\n",
    "e_F = X-mean(X)\n",
    "E_F = sum(e_F^2)\n",
    "E_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "420"
      ],
      "text/latex": [
       "420"
      ],
      "text/markdown": [
       "420"
      ],
      "text/plain": [
       "[1] 420"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Restricted model\n",
    "e_R = X-mu\n",
    "E_R = sum(e_R^2)\n",
    "E_R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the sum of squared errors is 270 for the full model and 420 for the restricted model. Now, let's get the degrees of freedom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full DF: 5 \n",
      "Restricted DF: 6"
     ]
    }
   ],
   "source": [
    "n = length(X)\n",
    "df_F = n-1\n",
    "df_R = n\n",
    "cat('Full DF:', df_F, '\\n') \n",
    "cat('Restricted DF:',df_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the pieces we need to calculate the $F$-statistic. We'll calculate according to the following formula:\n",
    "\n",
    "$$F = \\frac{(E_R-E_F)/(df_R-df_F)}{E_F/df_F}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "2.77777777777778"
      ],
      "text/latex": [
       "2.77777777777778"
      ],
      "text/markdown": [
       "2.77777777777778"
      ],
      "text/plain": [
       "[1] 2.777778"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = (E_R-E_F)/(df_R-df_F)\n",
    "denom = (E_F/df_F)\n",
    "F = num/denom\n",
    "F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so we have $F=2.778$. Since $df_{num}=1$ and $df_{denom}=5$, we look at the $F$-table to find $F_{crit}(1, 5)=6.6079$. This is much more extreme than $2.778$. So we do not have the evidence to claim that the more complex model performs significantly better than the simpler model. Just to check, we can calculate the $p$-value for $F=2.778$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.156457845340049"
      ],
      "text/latex": [
       "0.156457845340049"
      ],
      "text/markdown": [
       "0.156457845340049"
      ],
      "text/plain": [
       "[1] 0.1564578"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pf(F, df_R-df_F, df_F, lower.tail = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is indeed larger than $\\alpha=0.05$, and equals the $p$-value we obtained in #5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. How does the test statistic you computed in #6 relate to the one you computed in #5?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution.** The $F$-statistic in #6 is the square of the $t$-statistic in #5. We can quickly check to see that the square root of the $F$-statistic is equal to the $t$-statistic we observed (1.667):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all.equal(t, sqrt(F)) # checks out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Use R to carry out the analyses from #5 and #6. Paste your code and your output.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution.** See #5 and #6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. A researcher is interested in assessing the effectiveness of a prenatal care intervention on newborns’ birthweight. Adolescent pregnant women – who tend to have low birthweight infants – are identified and invited to participate in an experiment. Those who wish to participate are randomly assigned to one of two groups: an experimental group or a control group. Women in the experimental group participate in the prenatal care program, whereas women in the control group do not. After their babies were born, the following data were collected (DV = Newborn’s birthweight in lbs):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 10 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Experimental</th><th scope=col>Control</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>5.6</td><td>5.6</td></tr>\n",
       "\t<tr><td>7.7</td><td>6.4</td></tr>\n",
       "\t<tr><td>8.1</td><td>5.6</td></tr>\n",
       "\t<tr><td>7.6</td><td>5.9</td></tr>\n",
       "\t<tr><td>8.8</td><td>6.6</td></tr>\n",
       "\t<tr><td>7.5</td><td>7.4</td></tr>\n",
       "\t<tr><td>6.6</td><td>6.4</td></tr>\n",
       "\t<tr><td>8.4</td><td>7.0</td></tr>\n",
       "\t<tr><td>7.2</td><td>4.8</td></tr>\n",
       "\t<tr><td>7.5</td><td>4.3</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 10 × 2\n",
       "\\begin{tabular}{ll}\n",
       " Experimental & Control\\\\\n",
       " <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 5.6 & 5.6\\\\\n",
       "\t 7.7 & 6.4\\\\\n",
       "\t 8.1 & 5.6\\\\\n",
       "\t 7.6 & 5.9\\\\\n",
       "\t 8.8 & 6.6\\\\\n",
       "\t 7.5 & 7.4\\\\\n",
       "\t 6.6 & 6.4\\\\\n",
       "\t 8.4 & 7.0\\\\\n",
       "\t 7.2 & 4.8\\\\\n",
       "\t 7.5 & 4.3\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 10 × 2\n",
       "\n",
       "| Experimental &lt;dbl&gt; | Control &lt;dbl&gt; |\n",
       "|---|---|\n",
       "| 5.6 | 5.6 |\n",
       "| 7.7 | 6.4 |\n",
       "| 8.1 | 5.6 |\n",
       "| 7.6 | 5.9 |\n",
       "| 8.8 | 6.6 |\n",
       "| 7.5 | 7.4 |\n",
       "| 6.6 | 6.4 |\n",
       "| 8.4 | 7.0 |\n",
       "| 7.2 | 4.8 |\n",
       "| 7.5 | 4.3 |\n",
       "\n"
      ],
      "text/plain": [
       "   Experimental Control\n",
       "1  5.6          5.6    \n",
       "2  7.7          6.4    \n",
       "3  8.1          5.6    \n",
       "4  7.6          5.9    \n",
       "5  8.8          6.6    \n",
       "6  7.5          7.4    \n",
       "7  6.6          6.4    \n",
       "8  8.4          7.0    \n",
       "9  7.2          4.8    \n",
       "10 7.5          4.3    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Experimental <- c(5.6, 7.7, 8.1, 7.6, 8.8, 7.5, 6.6, 8.4, 7.2, 7.5)\n",
    "Control <- c(5.6, 6.4, 5.6, 5.9, 6.6, 7.4, 6.4, 7.0, 4.8, 4.3)\n",
    "Infants <- data.frame(cbind(Experimental, Control))\n",
    "Infants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the GLM model comparison approach, test whether the treatment program result in significantly different birthweights for the newborns. You may use R to do all of the calculations (e.g., to calculate means, $E_F$, and $E_R$), but be sure to write out the full and restricted models and show all necessary steps. Show any relevant code and output.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution.** Okay, the two-group approach is a little different. For the full model, we have to estimate the population mean for each group (so two), but for the restricted model, we assume that both groups come from the same population, and estimate only one population mean. The mean is 7.5 for the Experimental group, 6 for the Control group, and 6.75 for the grand mean. This gives us the following models:\n",
    "\n",
    "* Full: $Y_{ij} = \\mu_j+\\epsilon_{ij}$ where $\\mu_1=7.5$ and $\\mu_2=6$,\n",
    "* Restricted: $Y_{ij} = 6.75 + \\epsilon_{ij}$\n",
    "\n",
    "So, let's first get the sums of individual squared errors for both models ($E_F$ and $E_R$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "15.72"
      ],
      "text/latex": [
       "15.72"
      ],
      "text/markdown": [
       "15.72"
      ],
      "text/plain": [
       "[1] 15.72"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Full model\n",
    "e_F = c((Experimental-mean(Experimental)), (Control-mean(Control)))\n",
    "E_F = sum(e_F^2)\n",
    "E_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "26.97"
      ],
      "text/latex": [
       "26.97"
      ],
      "text/markdown": [
       "26.97"
      ],
      "text/plain": [
       "[1] 26.97"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Restricted model\n",
    "all = c(Experimental, Control)\n",
    "e_R = all-mean(all)\n",
    "E_R = sum(e_R^2)\n",
    "E_R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can get the degrees of freedom for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full DF: 18 \n",
      "Restricted DF: 19"
     ]
    }
   ],
   "source": [
    "N = length(all)\n",
    "df_F = N-2 # estimated two parameters: through mean(Experimental) and mean(Control)\n",
    "df_R = N-1 # estimated only one parameter: through mean(all)\n",
    "cat('Full DF:', df_F, '\\n') \n",
    "cat('Restricted DF:',df_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool. Now we can put them all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "12.881679389313"
      ],
      "text/latex": [
       "12.881679389313"
      ],
      "text/markdown": [
       "12.881679389313"
      ],
      "text/plain": [
       "[1] 12.88168"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = (E_R-E_F)/(df_R-df_F)\n",
    "denom = (E_F/df_F)\n",
    "F = num/denom\n",
    "F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking up $F_{crit}(1, 18)$, we obtain 4.4139. Our experimental $F=12.88$ is *much* more extreme than 4.4139. The full model does perform much better than the restricted model. So, we have a pretty solid basis for rejecting the null hypothesis—prenatal care in adolescent mothers does improve newborns' birth weights. Just to check, we can calculate the $p$-value, which is much smaller than $\\alpha=0.05$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0020974134920355"
      ],
      "text/latex": [
       "0.0020974134920355"
      ],
      "text/markdown": [
       "0.0020974134920355"
      ],
      "text/plain": [
       "[1] 0.002097413"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pf(F, df_R-df_F, df_F, lower.tail = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Use R to carry out an independent-samples t-test using the data from #9. What is the relationship between the test statistic you computed in #9 and the test statistic you computed in #10? Show any relevant code and output.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**. Doing a t-test gives us a $t$-statistic of 3.5891, and gives us the same $p$-value (0.002097) that we obtained in the GLM comparison in #9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tTwo Sample t-test\n",
       "\n",
       "data:  Experimental and Control\n",
       "t = 3.5891, df = 18, p-value = 0.002097\n",
       "alternative hypothesis: true difference in means is not equal to 0\n",
       "95 percent confidence interval:\n",
       " 0.6219587 2.3780413\n",
       "sample estimates:\n",
       "mean of x mean of y \n",
       "      7.5       6.0 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.test(Experimental, Control, alternative = \"two.sided\", var.equal = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $t$-statistic is still the square root of the $F$-statistic we obtained in #9 (the very small error coming from the significant figures cutoff):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Mean relative difference: 1.575082e-06'"
      ],
      "text/latex": [
       "'Mean relative difference: 1.575082e-06'"
      ],
      "text/markdown": [
       "'Mean relative difference: 1.575082e-06'"
      ],
      "text/plain": [
       "[1] \"Mean relative difference: 1.575082e-06\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all.equal(3.5891, sqrt(F))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
